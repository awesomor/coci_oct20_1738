<!doctype html>
<html lang="ko">
<head>
  <meta charset="utf-8" />
  <title>Wave Player + RMS VAD Chunking + Whisper (HTTP Proxy)</title>
  <link rel="stylesheet" href="/static/style.css" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    .stt-status{font-size:12px;color:#64748b;margin-left:8px}
    .chunk-item .pill{display:inline-block;width:12px;height:12px;border-radius:3px;margin-right:6px;background:#22c55e}
    .chunk-item.sending{opacity:.7}
    .chunk-text{color:#0f172a;margin-left:6px}
    .error{color:#ef4444}
  </style>
</head>
<body>
  <main class="container">
    <h1>ğŸ§ Wave Player + RMS ê¸°ë°˜ ì²­í‚¹(0.6s ë¬´ìŒ) â†’ Whisper (HTTP Proxy)</h1>

    <!-- ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´ -->
    <audio id="player" src="/media/sample.wav" controls class="audio"></audio>

    <!-- íŒŒí˜• ìº”ë²„ìŠ¤ -->
    <canvas id="wave-canvas" class="wave"></canvas>

    <!-- ì²­í¬ íƒ€ì„ë¼ì¸ (ì²­í¬ êµ¬ê°„ì´ ì´ˆë¡ ë§‰ëŒ€ë¡œ í‘œì‹œë¨) -->
    <div class="row">
      <label class="label">Chunks</label>
      <canvas id="chunk-canvas" class="chunk-timeline"></canvas>
    </div>

    <!-- ìƒíƒœ UI -->
    <div class="grid">
      <div>
        <div class="label">RMS (100ms)</div>
        <div id="rms-val" class="mono">0.0000</div>
      </div>
      <div>
        <div class="label">Threshold</div>
        <input id="thresh" type="range" min="0.01" max="0.10" step="0.005" value="0.03" />
        <div><span class="mono" id="thresh-val">0.03</span></div>
      </div>
      <div>
        <div class="label">Voice</div>
        <div id="voice-box" class="voice-indicator off"></div>
      </div>
      <div>
        <div class="label">Silence (ms)</div>
        <div id="silence-ms" class="mono">0</div>
      </div>
      <div>
        <div class="label">STT</div>
        <div class="stt-status"><span id="ws-state">HTTP /stt-proxy</span></div>
      </div>
    </div>

    <!-- ì²­í¬ ë¡œê·¸ -->
    <div class="row">
      <label class="label">Chunk Log (ì‹¤ì‹œê°„ ìë§‰ ë¶™ì„)</label>
      <div id="chunk-log" class="chunk-log"></div>
    </div>
  </main>

  <script>
    // ===========================
    // ì²­í‚¹ íŒŒë¼ë¯¸í„°
    // ===========================
    const SILENCE_MS_TO_SPLIT = 600;   // 0.6ì´ˆ ë¬´ìŒ ì§€ì† ì‹œ ì²­í¬ ì¢…ë£Œ
    const RMS_WINDOW_SEC = 0.1;        // 100ms RMS ê³„ì‚° ì°½
    const POLL_MS = 100;               // 100ms ì£¼ê¸°

    // ===========================
    // ì—˜ë¦¬ë¨¼íŠ¸
    // ===========================
    const playerEl = document.getElementById('player');
    const waveCanvas = document.getElementById('wave-canvas');
    const chunkCanvas = document.getElementById('chunk-canvas');
    const voiceBox = document.getElementById('voice-box');
    const rmsValEl = document.getElementById('rms-val');
    const threshEl = document.getElementById('thresh');
    const threshValEl = document.getElementById('thresh-val');
    const silenceMsEl = document.getElementById('silence-ms');
    const chunkLogEl = document.getElementById('chunk-log');
    const wsStateEl = document.getElementById('ws-state');

    // ===========================
    // ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸/ë²„í¼
    // ===========================
    let audioCtx = null;
    let audioBuffer = null;
    let channelData = null;
    let sampleRate = 48000;

    // ===========================
    // ìƒíƒœ ë¨¸ì‹ 
    // ===========================
    let threshold = parseFloat(threshEl.value);
    let pollingTimer = null;

    let isSpeaking = false;
    let currentChunkStart = null; // ì´ˆ ë‹¨ìœ„
    let silenceAccumMs = 0;
    const chunks = []; // {start, end, elInfo, text}

    // ===========================
    // ìœ í‹¸
    // ===========================
    function calculateRMS(samples) {
      let sum = 0;
      for (let i = 0; i < samples.length; i++) sum += samples[i] * samples[i];
      return Math.sqrt(sum / Math.max(1, samples.length));
    }

    function formatSec(sec) {
      return (Math.max(0, sec)).toFixed(2) + 's';
    }

    function drawWaveform() {
      const ctx = waveCanvas.getContext('2d');
      const w = waveCanvas.width = waveCanvas.clientWidth;
      const h = waveCanvas.height = waveCanvas.clientHeight;

      ctx.clearRect(0, 0, w, h);
      if (!channelData) return;

      ctx.lineWidth = 1;
      ctx.beginPath();

      const step = Math.ceil(channelData.length / w);
      const mid = h / 2;
      for (let x = 0; x < w; x++) {
        const start = x * step;
        const end = Math.min(start + step, channelData.length);
        let min = 1.0, max = -1.0;
        for (let i = start; i < end; i++) {
          const v = channelData[i];
          if (v < min) min = v;
          if (v > max) max = v;
        }
        ctx.moveTo(x, (1 - min) * mid);
        ctx.lineTo(x, (1 - max) * mid);
      }
      ctx.stroke();
    }

    function drawChunks() {
      const ctx = chunkCanvas.getContext('2d');
      const w = chunkCanvas.width = chunkCanvas.clientWidth;
      const h = chunkCanvas.height = chunkCanvas.clientHeight;

      ctx.clearRect(0, 0, w, h);

      if (!audioBuffer) return;
      const dur = audioBuffer.duration;

      // ì „ì²´ ë°” í‹€
      ctx.lineWidth = 1;
      ctx.strokeRect(0.5, 0.5, w - 1, h - 1);

      // ì´ë¯¸ í™•ì •ëœ ì²­í¬
      ctx.globalAlpha = 0.6;
      for (const c of chunks) {
        const x1 = (c.start / dur) * w;
        const x2 = (c.end / dur) * w;
        ctx.fillRect(x1, 0, Math.max(1, x2 - x1), h);
      }
      ctx.globalAlpha = 1.0;

      // ì§„í–‰ ì¤‘ì¸ ì²­í¬ ì‹œê°í™”
      if (isSpeaking && currentChunkStart != null) {
        const now = Math.min(playerEl.currentTime, dur);
        const x1 = (currentChunkStart / dur) * w;
        const x2 = (now / dur) * w;
        ctx.fillRect(x1, 0, Math.max(1, x2 - x1), h);
      }

      // í”Œë ˆì´í—¤ë“œ
      const headX = (playerEl.currentTime / dur) * w;
      ctx.beginPath();
      ctx.moveTo(headX, 0);
      ctx.lineTo(headX, h);
      ctx.stroke();
    }

    function setVoice(on) {
      voiceBox.classList.toggle('on', !!on);
      voiceBox.classList.toggle('off', !on);
    }

    function createChunkLogItem(chunk) {
      const div = document.createElement('div');
      div.className = 'chunk-item';
      const pill = document.createElement('span');
      pill.className = 'pill';
      const text = document.createElement('span');
      text.className = 'mono';
      text.textContent = `Chunk ${chunks.length}: ${formatSec(chunk.start)} ~ ${formatSec(chunk.end)} (len ${(chunk.end - chunk.start).toFixed(2)}s)`;
      const stt = document.createElement('span');
      stt.className = 'chunk-text';
      stt.textContent = ''; // Whisper í…ìŠ¤íŠ¸ ë“¤ì–´ê°ˆ ìë¦¬
      div.appendChild(pill);
      div.appendChild(text);
      div.appendChild(stt);
      chunkLogEl.prepend(div);
      return { container: div, sttEl: stt };
    }

    function renderChunkText(chunkRef) {
      if (!chunkRef || !chunkRef.elInfo) return;
      const { container, sttEl } = chunkRef.elInfo;
      container.classList.remove('sending');
      if (chunkRef.text && chunkRef.text.trim().length > 0) {
        sttEl.textContent = ' â†’ "' + chunkRef.text.trim() + '"';
        sttEl.classList.remove('error');
      } else {
        sttEl.textContent = ' â†’ (no text)';
        sttEl.classList.add('error');
      }
    }

    // ===========================
    // WAV ì¸ì½”ë”© (Mono, 16-bit PCM)
    // ===========================
    function floatTo16BitPCM(output, offset, input) {
      for (let i = 0; i < input.length; i++, offset += 2) {
        let s = Math.max(-1, Math.min(1, input[i]));
        s = s < 0 ? s * 0x8000 : s * 0x7FFF;
        output.setInt16(offset, s, true);
      }
    }

    function writeString(view, offset, string) {
      for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
      }
    }

    function encodeWAV(samples, sampleRate) {
      const numChannels = 1;
      const bytesPerSample = 2; // 16-bit
      const blockAlign = numChannels * bytesPerSample;
      const byteRate = sampleRate * blockAlign;
      const dataSize = samples.length * bytesPerSample;

      const buffer = new ArrayBuffer(44 + dataSize);
      const view = new DataView(buffer);

      // RIFF chunk descriptor
      writeString(view, 0, 'RIFF');
      view.setUint32(4, 36 + dataSize, true);
      writeString(view, 8, 'WAVE');

      // fmt sub-chunk
      writeString(view, 12, 'fmt ');
      view.setUint32(16, 16, true);           // Subchunk1Size (16 for PCM)
      view.setUint16(20, 1, true);            // AudioFormat (1 = PCM)
      view.setUint16(22, numChannels, true);
      view.setUint32(24, sampleRate, true);
      view.setUint32(28, byteRate, true);
      view.setUint16(32, blockAlign, true);
      view.setUint16(34, bytesPerSample * 8, true);

      // data sub-chunk
      writeString(view, 36, 'data');
      view.setUint32(40, dataSize, true);

      // PCM samples
      floatTo16BitPCM(view, 44, samples);

      return new Blob([view], { type: 'audio/wav' });
    }

    // ===========================
    // âœ… ì²­í¬ â†’ WAV â†’ /stt-proxy(HTTP) ì „ì†¡
    // ===========================
    async function sendChunkToWhisper_HTTP(chunkRef) {
      try {
        const startIdx = Math.max(0, Math.floor(chunkRef.start * sampleRate));
        const endIdx   = Math.min(channelData.length, Math.floor(chunkRef.end * sampleRate));
        const mono = channelData.subarray(startIdx, endIdx);

        const wavBlob = encodeWAV(mono, sampleRate);

        if (chunkRef.elInfo?.container) chunkRef.elInfo.container.classList.add('sending');

        const fd = new FormData();
        fd.append('file', wavBlob, 'chunk.wav');

        const resp = await fetch('/stt-proxy', {
          method: 'POST',
          body: fd,
        });

        const j = await resp.json();
        if (j.ok) {
          chunkRef.text = j.text || '';
          renderChunkText(chunkRef);
        } else {
          if (chunkRef.elInfo) {
            chunkRef.elInfo.container.classList.remove('sending');
            chunkRef.elInfo.sttEl.textContent = ' â†’ (error: ' + (j.error || `HTTP ${resp.status}`) + ')';
            chunkRef.elInfo.sttEl.classList.add('error');
          }
        }
      } catch (e) {
        if (chunkRef.elInfo) {
          chunkRef.elInfo.container.classList.remove('sending');
          chunkRef.elInfo.sttEl.textContent = ' â†’ (send failed)';
          chunkRef.elInfo.sttEl.classList.add('error');
        }
        console.error('sendChunkToWhisper_HTTP error', e);
      }
    }

    // ===========================
    // í´ë§ ë£¨í”„ (100ms)
    // ===========================
    function poll() {
      if (!audioBuffer) return;

      const sr = sampleRate;
      const windowSize = Math.floor(RMS_WINDOW_SEC * sr);

      const endIndex = Math.floor(playerEl.currentTime * sr);
      const startIndex = Math.max(0, endIndex - windowSize);

      const samples = channelData.subarray(startIndex, endIndex);
      const rms = calculateRMS(samples);

      // UI
      rmsValEl.textContent = rms.toFixed(4);
      setVoice(rms > threshold);

      // ìƒíƒœ ë¨¸ì‹ 
      const speakingNow = rms > threshold;

      if (speakingNow) {
        if (!isSpeaking) {
          isSpeaking = true;
          currentChunkStart = Math.max(0, playerEl.currentTime - RMS_WINDOW_SEC);
          silenceAccumMs = 0;
        } else {
          silenceAccumMs = 0;
        }
      } else {
        if (isSpeaking) {
          silenceAccumMs += POLL_MS;
          if (silenceAccumMs >= SILENCE_MS_TO_SPLIT) {
            const chunkEnd = Math.max(0, playerEl.currentTime - (silenceAccumMs / 1000));
            if (currentChunkStart != null && chunkEnd - currentChunkStart > 0.05) {
              const chunk = { start: currentChunkStart, end: chunkEnd, text: "" };
              const elInfo = createChunkLogItem(chunk);
              chunk.elInfo = elInfo;
              chunks.push(chunk);

              // ì¦‰ì‹œ Whisper ì „ì†¡ (HTTP)
              sendChunkToWhisper_HTTP(chunk);
            }
            isSpeaking = false;
            currentChunkStart = null;
            silenceAccumMs = 0;
          }
        } else {
          silenceAccumMs = Math.min(silenceAccumMs + POLL_MS, SILENCE_MS_TO_SPLIT);
        }
      }

      silenceMsEl.textContent = silenceAccumMs.toString();

      // ê·¸ë¦¬ê¸°
      drawChunks();
    }

    // ===========================
    // ë¡œë”© & ì´ˆê¸°í™”
    // ===========================
    async function initAudio() {
      wsStateEl.textContent = 'HTTP /stt-proxy';
      audioCtx = new (window.AudioContext || window.webkitAudioContext)();
      const res = await fetch(playerEl.src);
      if (!res.ok) {
        wsStateEl.textContent = "â— audio fetch failed";
        return;
      }
      const arrayBuf = await res.arrayBuffer();
      audioBuffer = await audioCtx.decodeAudioData(arrayBuf);
      sampleRate = audioBuffer.sampleRate;
      channelData = audioBuffer.getChannelData(0);

      drawWaveform();
      drawChunks();

      if (!pollingTimer) {
        pollingTimer = setInterval(poll, POLL_MS);
      }
    }

    // ì´ë²¤íŠ¸
    playerEl.addEventListener('play', () => { audioCtx && audioCtx.resume(); });
    playerEl.addEventListener('seeked', () => {
      silenceAccumMs = 0;
      drawChunks();
    });
    playerEl.addEventListener('ended', () => {
      if (isSpeaking && currentChunkStart != null) {
        const chunk = { start: currentChunkStart, end: audioBuffer.duration, text: "" };
        const elInfo = createChunkLogItem(chunk);
        chunk.elInfo = elInfo;
        chunks.push(chunk);
        // ì¦‰ì‹œ ì „ì†¡ (HTTP)
        sendChunkToWhisper_HTTP(chunk);
      }
      isSpeaking = false;
      currentChunkStart = null;
      silenceAccumMs = 0;
      drawChunks();
    });

    threshEl.addEventListener('input', (e) => {
      threshold = parseFloat(e.target.value);
      threshValEl.textContent = threshold.toFixed(3);
    });

    window.addEventListener('resize', () => {
      drawWaveform();
      drawChunks();
    });

    // ì‹œì‘
    initAudio();
  </script>
</body>
</html>
