<!doctype html>
<html lang="ko">
<head>
  <meta charset="utf-8" />
  <title>Wave Player + RMS VAD Chunking + Whisper (HTTP Proxy)</title>
  <link rel="stylesheet" href="/static/style.css" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    .stt-status{font-size:12px;color:#64748b;margin-left:8px}
    .chunk-item .pill{display:inline-block;width:12px;height:12px;border-radius:3px;margin-right:6px;background:#22c55e}
    .chunk-item.sending{opacity:.7}
    .chunk-text{color:#0f172a;margin-left:6px}
    .error{color:#ef4444}
  </style>
</head>
<body>
  <main class="container">
    <h1>🎧 Wave Player + RMS 기반 청킹(0.6s 무음) → Whisper (HTTP Proxy)</h1>

    <!-- 오디오 플레이어 -->
    <audio id="player" src="/media/sample.wav" controls class="audio"></audio>

    <!-- 파형 캔버스 -->
    <canvas id="wave-canvas" class="wave"></canvas>

    <!-- 청크 타임라인 (청크 구간이 초록 막대로 표시됨) -->
    <div class="row">
      <label class="label">Chunks</label>
      <canvas id="chunk-canvas" class="chunk-timeline"></canvas>
    </div>

    <!-- 상태 UI -->
    <div class="grid">
      <div>
        <div class="label">RMS (100ms)</div>
        <div id="rms-val" class="mono">0.0000</div>
      </div>
      <div>
        <div class="label">Threshold</div>
        <input id="thresh" type="range" min="0.01" max="0.10" step="0.005" value="0.03" />
        <div><span class="mono" id="thresh-val">0.03</span></div>
      </div>
      <div>
        <div class="label">Voice</div>
        <div id="voice-box" class="voice-indicator off"></div>
      </div>
      <div>
        <div class="label">Silence (ms)</div>
        <div id="silence-ms" class="mono">0</div>
      </div>
      <div>
        <div class="label">STT</div>
        <div class="stt-status"><span id="ws-state">HTTP /stt-proxy</span></div>
      </div>
    </div>

    <!-- 청크 로그 -->
    <div class="row">
      <label class="label">Chunk Log (실시간 자막 붙임)</label>
      <div id="chunk-log" class="chunk-log"></div>
    </div>
  </main>

  <script>
    // ===========================
    // 청킹 파라미터
    // ===========================
    const SILENCE_MS_TO_SPLIT = 600;   // 0.6초 무음 지속 시 청크 종료
    const RMS_WINDOW_SEC = 0.1;        // 100ms RMS 계산 창
    const POLL_MS = 100;               // 100ms 주기

    // ===========================
    // 엘리먼트
    // ===========================
    const playerEl = document.getElementById('player');
    const waveCanvas = document.getElementById('wave-canvas');
    const chunkCanvas = document.getElementById('chunk-canvas');
    const voiceBox = document.getElementById('voice-box');
    const rmsValEl = document.getElementById('rms-val');
    const threshEl = document.getElementById('thresh');
    const threshValEl = document.getElementById('thresh-val');
    const silenceMsEl = document.getElementById('silence-ms');
    const chunkLogEl = document.getElementById('chunk-log');
    const wsStateEl = document.getElementById('ws-state');

    // ===========================
    // 오디오 컨텍스트/버퍼
    // ===========================
    let audioCtx = null;
    let audioBuffer = null;
    let channelData = null;
    let sampleRate = 48000;

    // ===========================
    // 상태 머신
    // ===========================
    let threshold = parseFloat(threshEl.value);
    let pollingTimer = null;

    let isSpeaking = false;
    let currentChunkStart = null; // 초 단위
    let silenceAccumMs = 0;
    const chunks = []; // {start, end, elInfo, text}

    // ===========================
    // 유틸
    // ===========================
    function calculateRMS(samples) {
      let sum = 0;
      for (let i = 0; i < samples.length; i++) sum += samples[i] * samples[i];
      return Math.sqrt(sum / Math.max(1, samples.length));
    }

    function formatSec(sec) {
      return (Math.max(0, sec)).toFixed(2) + 's';
    }

    function drawWaveform() {
      const ctx = waveCanvas.getContext('2d');
      const w = waveCanvas.width = waveCanvas.clientWidth;
      const h = waveCanvas.height = waveCanvas.clientHeight;

      ctx.clearRect(0, 0, w, h);
      if (!channelData) return;

      ctx.lineWidth = 1;
      ctx.beginPath();

      const step = Math.ceil(channelData.length / w);
      const mid = h / 2;
      for (let x = 0; x < w; x++) {
        const start = x * step;
        const end = Math.min(start + step, channelData.length);
        let min = 1.0, max = -1.0;
        for (let i = start; i < end; i++) {
          const v = channelData[i];
          if (v < min) min = v;
          if (v > max) max = v;
        }
        ctx.moveTo(x, (1 - min) * mid);
        ctx.lineTo(x, (1 - max) * mid);
      }
      ctx.stroke();
    }

    function drawChunks() {
      const ctx = chunkCanvas.getContext('2d');
      const w = chunkCanvas.width = chunkCanvas.clientWidth;
      const h = chunkCanvas.height = chunkCanvas.clientHeight;

      ctx.clearRect(0, 0, w, h);

      if (!audioBuffer) return;
      const dur = audioBuffer.duration;

      // 전체 바 틀
      ctx.lineWidth = 1;
      ctx.strokeRect(0.5, 0.5, w - 1, h - 1);

      // 이미 확정된 청크
      ctx.globalAlpha = 0.6;
      for (const c of chunks) {
        const x1 = (c.start / dur) * w;
        const x2 = (c.end / dur) * w;
        ctx.fillRect(x1, 0, Math.max(1, x2 - x1), h);
      }
      ctx.globalAlpha = 1.0;

      // 진행 중인 청크 시각화
      if (isSpeaking && currentChunkStart != null) {
        const now = Math.min(playerEl.currentTime, dur);
        const x1 = (currentChunkStart / dur) * w;
        const x2 = (now / dur) * w;
        ctx.fillRect(x1, 0, Math.max(1, x2 - x1), h);
      }

      // 플레이헤드
      const headX = (playerEl.currentTime / dur) * w;
      ctx.beginPath();
      ctx.moveTo(headX, 0);
      ctx.lineTo(headX, h);
      ctx.stroke();
    }

    function setVoice(on) {
      voiceBox.classList.toggle('on', !!on);
      voiceBox.classList.toggle('off', !on);
    }

    function createChunkLogItem(chunk) {
      const div = document.createElement('div');
      div.className = 'chunk-item';
      const pill = document.createElement('span');
      pill.className = 'pill';
      const text = document.createElement('span');
      text.className = 'mono';
      text.textContent = `Chunk ${chunks.length}: ${formatSec(chunk.start)} ~ ${formatSec(chunk.end)} (len ${(chunk.end - chunk.start).toFixed(2)}s)`;
      const stt = document.createElement('span');
      stt.className = 'chunk-text';
      stt.textContent = ''; // Whisper 텍스트 들어갈 자리
      div.appendChild(pill);
      div.appendChild(text);
      div.appendChild(stt);
      chunkLogEl.prepend(div);
      return { container: div, sttEl: stt };
    }

    function renderChunkText(chunkRef) {
      if (!chunkRef || !chunkRef.elInfo) return;
      const { container, sttEl } = chunkRef.elInfo;
      container.classList.remove('sending');
      if (chunkRef.text && chunkRef.text.trim().length > 0) {
        sttEl.textContent = ' → "' + chunkRef.text.trim() + '"';
        sttEl.classList.remove('error');
      } else {
        sttEl.textContent = ' → (no text)';
        sttEl.classList.add('error');
      }
    }

    // ===========================
    // WAV 인코딩 (Mono, 16-bit PCM)
    // ===========================
    function floatTo16BitPCM(output, offset, input) {
      for (let i = 0; i < input.length; i++, offset += 2) {
        let s = Math.max(-1, Math.min(1, input[i]));
        s = s < 0 ? s * 0x8000 : s * 0x7FFF;
        output.setInt16(offset, s, true);
      }
    }

    function writeString(view, offset, string) {
      for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
      }
    }

    function encodeWAV(samples, sampleRate) {
      const numChannels = 1;
      const bytesPerSample = 2; // 16-bit
      const blockAlign = numChannels * bytesPerSample;
      const byteRate = sampleRate * blockAlign;
      const dataSize = samples.length * bytesPerSample;

      const buffer = new ArrayBuffer(44 + dataSize);
      const view = new DataView(buffer);

      // RIFF chunk descriptor
      writeString(view, 0, 'RIFF');
      view.setUint32(4, 36 + dataSize, true);
      writeString(view, 8, 'WAVE');

      // fmt sub-chunk
      writeString(view, 12, 'fmt ');
      view.setUint32(16, 16, true);           // Subchunk1Size (16 for PCM)
      view.setUint16(20, 1, true);            // AudioFormat (1 = PCM)
      view.setUint16(22, numChannels, true);
      view.setUint32(24, sampleRate, true);
      view.setUint32(28, byteRate, true);
      view.setUint16(32, blockAlign, true);
      view.setUint16(34, bytesPerSample * 8, true);

      // data sub-chunk
      writeString(view, 36, 'data');
      view.setUint32(40, dataSize, true);

      // PCM samples
      floatTo16BitPCM(view, 44, samples);

      return new Blob([view], { type: 'audio/wav' });
    }

    // ===========================
    // ✅ 청크 → WAV → /stt-proxy(HTTP) 전송
    // ===========================
    async function sendChunkToWhisper_HTTP(chunkRef) {
      try {
        const startIdx = Math.max(0, Math.floor(chunkRef.start * sampleRate));
        const endIdx   = Math.min(channelData.length, Math.floor(chunkRef.end * sampleRate));
        const mono = channelData.subarray(startIdx, endIdx);

        const wavBlob = encodeWAV(mono, sampleRate);

        if (chunkRef.elInfo?.container) chunkRef.elInfo.container.classList.add('sending');

        const fd = new FormData();
        fd.append('file', wavBlob, 'chunk.wav');

        const resp = await fetch('/stt-proxy', {
          method: 'POST',
          body: fd,
        });

        const j = await resp.json();
        if (j.ok) {
          chunkRef.text = j.text || '';
          renderChunkText(chunkRef);
        } else {
          if (chunkRef.elInfo) {
            chunkRef.elInfo.container.classList.remove('sending');
            chunkRef.elInfo.sttEl.textContent = ' → (error: ' + (j.error || `HTTP ${resp.status}`) + ')';
            chunkRef.elInfo.sttEl.classList.add('error');
          }
        }
      } catch (e) {
        if (chunkRef.elInfo) {
          chunkRef.elInfo.container.classList.remove('sending');
          chunkRef.elInfo.sttEl.textContent = ' → (send failed)';
          chunkRef.elInfo.sttEl.classList.add('error');
        }
        console.error('sendChunkToWhisper_HTTP error', e);
      }
    }

    // ===========================
    // 폴링 루프 (100ms)
    // ===========================
    function poll() {
      if (!audioBuffer) return;

      const sr = sampleRate;
      const windowSize = Math.floor(RMS_WINDOW_SEC * sr);

      const endIndex = Math.floor(playerEl.currentTime * sr);
      const startIndex = Math.max(0, endIndex - windowSize);

      const samples = channelData.subarray(startIndex, endIndex);
      const rms = calculateRMS(samples);

      // UI
      rmsValEl.textContent = rms.toFixed(4);
      setVoice(rms > threshold);

      // 상태 머신
      const speakingNow = rms > threshold;

      if (speakingNow) {
        if (!isSpeaking) {
          isSpeaking = true;
          currentChunkStart = Math.max(0, playerEl.currentTime - RMS_WINDOW_SEC);
          silenceAccumMs = 0;
        } else {
          silenceAccumMs = 0;
        }
      } else {
        if (isSpeaking) {
          silenceAccumMs += POLL_MS;
          if (silenceAccumMs >= SILENCE_MS_TO_SPLIT) {
            const chunkEnd = Math.max(0, playerEl.currentTime - (silenceAccumMs / 1000));
            if (currentChunkStart != null && chunkEnd - currentChunkStart > 0.05) {
              const chunk = { start: currentChunkStart, end: chunkEnd, text: "" };
              const elInfo = createChunkLogItem(chunk);
              chunk.elInfo = elInfo;
              chunks.push(chunk);

              // 즉시 Whisper 전송 (HTTP)
              sendChunkToWhisper_HTTP(chunk);
            }
            isSpeaking = false;
            currentChunkStart = null;
            silenceAccumMs = 0;
          }
        } else {
          silenceAccumMs = Math.min(silenceAccumMs + POLL_MS, SILENCE_MS_TO_SPLIT);
        }
      }

      silenceMsEl.textContent = silenceAccumMs.toString();

      // 그리기
      drawChunks();
    }

    // ===========================
    // 로딩 & 초기화
    // ===========================
    async function initAudio() {
      wsStateEl.textContent = 'HTTP /stt-proxy';
      audioCtx = new (window.AudioContext || window.webkitAudioContext)();
      const res = await fetch(playerEl.src);
      if (!res.ok) {
        wsStateEl.textContent = "❗ audio fetch failed";
        return;
      }
      const arrayBuf = await res.arrayBuffer();
      audioBuffer = await audioCtx.decodeAudioData(arrayBuf);
      sampleRate = audioBuffer.sampleRate;
      channelData = audioBuffer.getChannelData(0);

      drawWaveform();
      drawChunks();

      if (!pollingTimer) {
        pollingTimer = setInterval(poll, POLL_MS);
      }
    }

    // 이벤트
    playerEl.addEventListener('play', () => { audioCtx && audioCtx.resume(); });
    playerEl.addEventListener('seeked', () => {
      silenceAccumMs = 0;
      drawChunks();
    });
    playerEl.addEventListener('ended', () => {
      if (isSpeaking && currentChunkStart != null) {
        const chunk = { start: currentChunkStart, end: audioBuffer.duration, text: "" };
        const elInfo = createChunkLogItem(chunk);
        chunk.elInfo = elInfo;
        chunks.push(chunk);
        // 즉시 전송 (HTTP)
        sendChunkToWhisper_HTTP(chunk);
      }
      isSpeaking = false;
      currentChunkStart = null;
      silenceAccumMs = 0;
      drawChunks();
    });

    threshEl.addEventListener('input', (e) => {
      threshold = parseFloat(e.target.value);
      threshValEl.textContent = threshold.toFixed(3);
    });

    window.addEventListener('resize', () => {
      drawWaveform();
      drawChunks();
    });

    // 시작
    initAudio();
  </script>
</body>
</html>
